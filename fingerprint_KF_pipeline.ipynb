{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fingerprint recognition pipeline in Kubeflow\n",
    "\n",
    "In this notebook, the **fingerprint recognition notebook** is segmented into components and executed as a **Kubeflow pipeline** run. A pipeline is a description of an ML workflow that includes all of the steps in the form of components in the workflow. A pipeline component is a self-contained set of user code, packaged as a Docker image, that performs one step in the pipeline. For example, this can be a component responsible for data preprocessing, data transformation, model training, and so on. For a conventional data science notebook to run as a Kubeflow pipeline it has to be brought into a Kubeflow *friendly* format which this notebook is dedicated to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pics](pics/fingerprint_Kubeflow.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load resuable components, define data location & name, MinIO, and namespace\n",
    "\n",
    "Reusable components for repetitive steps are loaded in the first step. The components are located in a coworker's github as a **.yaml** file and have to be loaded using the url path. Kubeflow is designed to allow data scientists to reuse components when they execute a step of the ML workflow that happens frequently, for example downloading the data into the notebook. Other components that can be reused here are for model conversion, model upload and model deployment. The components for those steps are only compatible with models trained using *tensorflow*. For models using other frameworks, other components need to be loaded or the component needs to be defined in the notebook.\n",
    "\n",
    "The dataset used in this notebook was uploaded to the file hosting service box. The URL and file name is mentioned next as well as the model name. Kubeflow ships with MinIO inside to store all of its pipelines, artifacts and logs. The URL, username and password must be called here. \n",
    "\n",
    "Kubeflow comes with multi-user isolation which simplifies user operations because each user only views and edits the Kubeflow components and model artifacts defined in their configuration. Isolation uses Kubernetes **Namespaces**. The Namespace needs to be specified before the other steps of the pipeline can be defined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'user-example-com'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DOWNLOAD_AND_EXTRACT_COMPONENT_URL = \"https://raw.githubusercontent.com/lehrig/kubeflow-ppc64le-components/main/data-extraction/download-and-extract-from-url/component.yaml\"\n",
    "CONVERT_MODEL_TO_ONNX_COMPONENT_URL = \"https://raw.githubusercontent.com/lehrig/kubeflow-ppc64le-components/main/model-building/convert-to-onnx/component.yaml\"\n",
    "UPLOAD_MODEL_COMPONENT_URL = \"https://raw.githubusercontent.com/lehrig/kubeflow-ppc64le-components/main/model-building/upload-model/component.yaml\"\n",
    "DEPLOY_MODEL_WITH_KSERVE_COMPONENT_URL = \"https://raw.githubusercontent.com/lehrig/kubeflow-ppc64le-components/main/model-deployment/deploy-model-with-kserve/component.yaml\"\n",
    "\n",
    "DATASET_URL = \"https://ibm.box.com/shared/static/cr1dmse8ehk1ywanxws12gkbf30tsgp5.zip\"\n",
    "DATASET_FILE_NAME = \"data.zip\"\n",
    "MODEL_NAME = \"fingerprint-classification\"\n",
    "\n",
    "MINIO_URL = \"minio-service.kubeflow:9000\"\n",
    "MINIO_USER = \"minio\"\n",
    "MINIO_PASS = \"minio123\"\n",
    "\n",
    "with open(\"/var/run/secrets/kubernetes.io/serviceaccount/namespace\") as f:\n",
    "    NAMESPACE = f.read()\n",
    "NAMESPACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "import kfp.components as comp\n",
    "from typing import NamedTuple\n",
    "import kfp.dsl as dsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = kfp.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "## 1.1 Load Dataset\n",
    "The first component download the data and extracts it from a zip file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_and_extract_comp = comp.load_component_from_url(\n",
    "    DOWNLOAD_AND_EXTRACT_COMPONENT_URL\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Preprocessing\n",
    "In the second component all the preprocessing is done before the data can be used to train the model. The data scientist has to decide which steps qualify as preprocessing steps and incorporates the code pieces into this component. In this example, the various image files are loaded, concatenated and then the train and test split is performed.\n",
    "\n",
    "Besides the preprocessing code, the component follows a clear logic where **Input** and **Output paths** are defined at the top, **packages & modules** are imported, **data** is imported, and after all the relevant code is inserted the data gets saved to a **new data directory** and the component receives a **base image** that contains all the relevant packages needed to run the code inside the component. This logic stays the same for every subsequent component. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "51e6ac44185ff301d77ff5c70358ed63a0cba055"
   },
   "outputs": [],
   "source": [
    "def preprocess_data(\n",
    "    data_dir: comp.InputPath(str),\n",
    "    prep_data_dir: comp.OutputPath(str)\n",
    "):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    import numpy as np\n",
    "    import os\n",
    "\n",
    "    x_real = np.load(f'{data_dir}/x_real.npz')['data']\n",
    "    y_real = np.load(f'{data_dir}/y_real.npy')\n",
    "    x_easy = np.load(f'{data_dir}/x_easy.npz')['data']\n",
    "    y_easy = np.load(f'{data_dir}/y_easy.npy')\n",
    "    x_medium = np.load(f'{data_dir}/x_medium.npz')['data']\n",
    "    y_medium = np.load(f'{data_dir}/y_medium.npy')\n",
    "    x_hard = np.load(f'{data_dir}/x_hard.npz')['data']\n",
    "    y_hard = np.load(f'{data_dir}/y_hard.npy')\n",
    "    \n",
    "    x_data = np.concatenate([x_easy, x_medium, x_hard], axis=0)\n",
    "    label_data = np.concatenate([y_easy, y_medium, y_hard], axis=0)\n",
    "\n",
    "    x_train, x_val, label_train, label_val = train_test_split(x_data, label_data, test_size=0.1)\n",
    "\n",
    "    print(x_data.shape, label_data.shape)\n",
    "    print(x_train.shape, label_train.shape)\n",
    "    print(x_val.shape, label_val.shape)\n",
    "    print(len(x_real), len(y_real))\n",
    "    \n",
    "    if not os.path.exists(prep_data_dir):\n",
    "        os.makedirs(prep_data_dir)\n",
    "            \n",
    "    np.savez(f'/{prep_data_dir}/train_data.npz', x_train, laWhatWhatbel_train)\n",
    "    np.savez(f'/{prep_data_dir}/val_data.npz', x_val, label_val)\n",
    "    np.savez(f'/{prep_data_dir}/real_data.npz', x_real, y_real)\n",
    "    \n",
    "    \n",
    "preprocess_data_comp = kfp.components.create_component_from_func(\n",
    "    func=preprocess_data,\n",
    "    output_component_file='prep_data_component.yaml',\n",
    "    base_image='quay.io/mgiessing/kubeflow-component-data-prep:latest',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Train the model\n",
    "In this component the model is trained and then it gets saved to the **model directory**. Before the model is trained the data is first augmented. Since the **data augmentation** has a direct effect on the training data it was decided to perform the data augmentation in this component. The data augmentation is performed on both the training and validation data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "2c0277fbf776834bb59da61eb5a73ce385a40209"
   },
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    prep_data_dir: comp.InputPath(str),\n",
    "    model_dir: comp.OutputPath(str)\n",
    "):\n",
    "    \"\"\"Uses transfer learning for 5 epochs on a prepared dataset. Once trained, the model is persisted to `model_dir`.\"\"\"\n",
    "\n",
    "    import os, random\n",
    "    import numpy as np\n",
    "    import tensorflow.keras as keras\n",
    "    from sklearn.utils import shuffle\n",
    "    from tensorflow.keras import Sequential\n",
    "    from tensorflow.keras.models import Model\n",
    "    from tensorflow.keras.applications import InceptionV3\n",
    "    from tensorflow.keras import layers\n",
    "    from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, BatchNormalization\n",
    "    from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "    from imgaug import augmenters as iaa\n",
    "\n",
    "\n",
    "    train_data = np.load(f'{prep_data_dir}/train_data.npz')\n",
    "    x_train = train_data[train_data.files[0]]\n",
    "    label_train = train_data[train_data.files[1]]\n",
    "    \n",
    "    val_data = np.load(f'{prep_data_dir}/val_data.npz')\n",
    "    x_val = val_data[val_data.files[0]]\n",
    "    label_val = val_data[val_data.files[1]]\n",
    "    \n",
    "    real_data = np.load(f'{prep_data_dir}/real_data.npz')\n",
    "    x_real = real_data[real_data.files[0]]\n",
    "    y_real = real_data[real_data.files[1]]\n",
    "    \n",
    "    label_real_dict = {}\n",
    "    for i, y in enumerate(y_real):\n",
    "        key = y.astype(str)\n",
    "        key = ''.join(key).zfill(6)\n",
    "\n",
    "        label_real_dict[key] = i\n",
    "    \n",
    "    class DataGenerator(keras.utils.Sequence):\n",
    "        def __init__(self, x, label, x_real, label_real_dict, batch_size=16, shuffle=True):\n",
    "            'Initialization'\n",
    "            self.x = x\n",
    "            self.label = label\n",
    "            self.x_real = x_real\n",
    "            self.label_real_dict = label_real_dict\n",
    "\n",
    "            self.batch_size = batch_size\n",
    "            self.shuffle = shuffle\n",
    "            self.on_epoch_end()\n",
    "\n",
    "        def __len__(self):\n",
    "            'Denotes the number of batches per epoch'\n",
    "            return int(np.floor(len(self.x) / self.batch_size))\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            'Generate one batch of data'\n",
    "            # Generate indexes of the batch\n",
    "            x1_batch = self.x[index*self.batch_size:(index+1)*self.batch_size]\n",
    "            label_batch = self.label[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "            x2_batch = np.empty((self.batch_size, 90, 90, 1), dtype=np.float32)\n",
    "            y_batch = np.zeros((self.batch_size, 1), dtype=np.float32)\n",
    "\n",
    "            # augmentation\n",
    "            if self.shuffle:\n",
    "                seq = iaa.Sequential([\n",
    "                    iaa.GaussianBlur(sigma=(0, 0.5)),\n",
    "                    iaa.Affine(\n",
    "                        scale={\"x\": (0.9, 1.1), \"y\": (0.9, 1.1)},\n",
    "                        translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)},\n",
    "                        rotate=(-30, 30),\n",
    "                        order=[0, 1],\n",
    "                        cval=255\n",
    "                    )\n",
    "                ], random_order=True)\n",
    "\n",
    "                x1_batch = seq.augment_images(x1_batch)\n",
    "\n",
    "            # pick matched images(label 1.0) and unmatched images(label 0.0) and put together in batch\n",
    "            # matched images must be all same, [subject_id(3), gender(1), left_right(1), finger(1)], e.g) 034010\n",
    "            for i, l in enumerate(label_batch):\n",
    "                match_key = l.astype(str)\n",
    "                match_key = ''.join(match_key).zfill(6)\n",
    "\n",
    "                if random.random() > 0.5:\n",
    "                    # put matched image\n",
    "                    x2_batch[i] = self.x_real[self.label_real_dict[match_key]]\n",
    "                    y_batch[i] = 1.\n",
    "                else:\n",
    "                    # put unmatched image\n",
    "                    while True:\n",
    "                        unmatch_key, unmatch_idx = random.choice(list(self.label_real_dict.items()))\n",
    "\n",
    "                        if unmatch_key != match_key:\n",
    "                            break\n",
    "\n",
    "                    x2_batch[i] = self.x_real[unmatch_idx]\n",
    "                    y_batch[i] = 0.\n",
    "\n",
    "            return [x1_batch.astype(np.float32) / 255., x2_batch.astype(np.float32) / 255.], y_batch\n",
    "\n",
    "        def on_epoch_end(self):\n",
    "            if self.shuffle == True:\n",
    "                self.x, self.label = shuffle(self.x, self.label)\n",
    "\n",
    "    train_gen = DataGenerator(x_train, label_train, x_real, label_real_dict, shuffle=False)\n",
    "    val_gen = DataGenerator(x_val, label_val, x_real, label_real_dict, shuffle=False)\n",
    "    \n",
    "    \n",
    "    x1 = layers.Input(shape=(90, 90, 1))\n",
    "    x2 = layers.Input(shape=(90, 90, 1))\n",
    "\n",
    "    # share weights both inputs\n",
    "    inputs = layers.Input(shape=(90, 90, 1))\n",
    "\n",
    "    feature = layers.Conv2D(32, kernel_size=3, padding='same', activation='relu')(inputs)\n",
    "    feature = layers.MaxPooling2D(pool_size=2)(feature)\n",
    "\n",
    "    feature = layers.Conv2D(32, kernel_size=3, padding='same', activation='relu')(feature)\n",
    "    feature = layers.MaxPooling2D(pool_size=2)(feature)\n",
    "\n",
    "    feature_model = Model(inputs=inputs, outputs=feature)\n",
    "\n",
    "    # 2 feature models that sharing weights\n",
    "    x1_net = feature_model(x1)\n",
    "    x2_net = feature_model(x2)\n",
    "\n",
    "    # subtract features\n",
    "    net = layers.Subtract()([x1_net, x2_net])\n",
    "\n",
    "    net = layers.Conv2D(32, kernel_size=3, padding='same', activation='relu')(net)\n",
    "    net = layers.MaxPooling2D(pool_size=2)(net)\n",
    "\n",
    "    net = layers.Flatten()(net)\n",
    "\n",
    "    net = layers.Dense(64, activation='relu')(net)\n",
    "\n",
    "    net = layers.Dense(1, activation='sigmoid')(net)\n",
    "\n",
    "    model = Model(inputs=[x1, x2], outputs=net)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "        \n",
    "    history = model.fit_generator(train_gen, epochs=3, validation_data=val_gen)\n",
    "    \n",
    "    model.save(model_dir)\n",
    "    \n",
    "train_model_comp = kfp.components.create_component_from_func(\n",
    "    func=train_model,\n",
    "    output_component_file='train_model_component.yaml',\n",
    "    base_image='quay.io/sabrinakopecki/imageaugmenttraintestplit:1.3'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9f7e646b3f6cce84fb8cbfd243be9bab723a44e7"
   },
   "source": [
    "## 1.4 Model evaluation\n",
    "This component does the evaluation of the model. The necessary packages and data from previously created directories are loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "5faca33e82001786e9c2fc83b6ec93fd2cca2059"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(\n",
    "    prep_data_dir: comp.InputPath(str),\n",
    "    model_dir: comp.InputPath(str),\n",
    "):\n",
    "    \"\"\"Loads a saved model from file and uses a pre-downloaded dataset for evaluation.\n",
    "    Model metrics are persisted to `/mlpipeline-metrics.json` for Kubeflow Pipelines\n",
    "    metadata.\"\"\"\n",
    "    \n",
    "    import json, random\n",
    "    import numpy as np\n",
    "    import tensorflow as tf\n",
    "    from sklearn.utils import shuffle\n",
    "    from imgaug import augmenters as iaa\n",
    "    from collections import namedtuple\n",
    "\n",
    "    val_data = np.load(f'{prep_data_dir}/val_data.npz')\n",
    "    x_val = val_data[val_data.files[0]]\n",
    "    label_val = val_data[val_data.files[1]]\n",
    "\n",
    "    real_data = np.load(f'{prep_data_dir}/real_data.npz')\n",
    "    x_real = real_data[real_data.files[0]]\n",
    "    y_real = real_data[real_data.files[1]]\n",
    "    \n",
    "    model = tf.keras.models.load_model(model_dir)\n",
    "\n",
    "    label_real_dict = {}\n",
    "    for i, y in enumerate(y_real):\n",
    "        key = y.astype(str)\n",
    "        key = ''.join(key).zfill(6)\n",
    "        label_real_dict[key] = i\n",
    "    \n",
    "    # new user fingerprint input\n",
    "    random_idx = random.randint(0, len(x_val))\n",
    "\n",
    "    random_img = x_val[random_idx]\n",
    "    random_label = label_val[random_idx]\n",
    "\n",
    "    seq = iaa.Sequential([\n",
    "        iaa.GaussianBlur(sigma=(0, 0.5)),\n",
    "        iaa.Affine(\n",
    "            scale={\"x\": (0.9, 1.1), \"y\": (0.9, 1.1)},\n",
    "            translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)},\n",
    "            rotate=(-30, 30),\n",
    "            order=[0, 1],\n",
    "            cval=255\n",
    "        )\n",
    "    ], random_order=True)\n",
    "\n",
    "    random_img = seq.augment_image(random_img).reshape((1, 90, 90, 1)).astype(np.float32) / 255.\n",
    "\n",
    "    # matched image\n",
    "    match_key = random_label.astype(str)\n",
    "    match_key = ''.join(match_key).zfill(6)\n",
    "\n",
    "    print(len(x_real), len(label_real_dict))\n",
    "    \n",
    "    rx = x_real[label_real_dict[match_key]].reshape((1, 90, 90, 1)).astype(np.float32) / 255.\n",
    "    ry = y_real[label_real_dict[match_key]]\n",
    "\n",
    "    pred_rx = model.predict([random_img, rx])\n",
    "\n",
    "    # unmatched image\n",
    "    unmatch_key, unmatch_idx = random.choice(list(label_real_dict.items()))\n",
    "\n",
    "    ux = x_real[unmatch_idx].reshape((1, 90, 90, 1)).astype(np.float32) / 255.\n",
    "    uy = y_real[unmatch_idx]\n",
    "\n",
    "    pred_ux = model.predict([random_img, ux])\n",
    "    \n",
    "    print(pred_ux)\n",
    "\n",
    "evaluate_model_comp = kfp.components.create_component_from_func(\n",
    "    func=evaluate_model,\n",
    "    output_component_file='evaluate_model_component.yaml',\n",
    "    base_image='quay.io/sabrinakopecki/imageaugmenttraintestplit:1.3'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Convert model to ONNX (by reusing a Kubeflow component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_model_to_onnx_comp = comp.load_component_from_url(\n",
    "    CONVERT_MODEL_TO_ONNX_COMPONENT_URL\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Upload model to MinIO artifact store (by reusing a Kubeflow component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_model_comp = comp.load_component_from_url(\n",
    "    UPLOAD_MODEL_COMPONENT_URL\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Deploy the model using KServe (by reusing a Kubeflow component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_model_with_kserve_comp = comp.load_component_from_url(\n",
    "    DEPLOY_MODEL_WITH_KSERVE_COMPONENT_URL\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ef08e0d5b86c994c01b64cf56b29a6039e607a48"
   },
   "source": [
    "## 2 Pipeline\n",
    "After all the components have been specified, the pipeline is defined using the **@dsl.pipeline** decorator. The pipeline determines the succession of components to run and which parameters to pass between them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "  name='Fingerprint classification pipeline',\n",
    "  description='fingerprint pipeline that matches images of fingerprints'\n",
    ")\n",
    "def fingerprint_pipeline(dataset_url: str,\n",
    "                    dataset_file_name: str = \"data.zip\",\n",
    "                    data_dir: str = \"/train/data\",\n",
    "                    prep_data_dir: str = \"/train/prep_data\",\n",
    "                    model_dir: str = \"/train/model\",\n",
    "                    model_name: str = \"fingerprint-recognition\",\n",
    "                    minio_url: str = MINIO_URL,\n",
    "                    minio_user: str = MINIO_USER,\n",
    "                    minio_pass: str = MINIO_PASS):\n",
    "    download_and_extract_task = download_and_extract_comp(\n",
    "        url=dataset_url,\n",
    "        file_name=dataset_file_name\n",
    "    )\n",
    "\n",
    "    preprocess_data_task = preprocess_data_comp(\n",
    "        download_and_extract_task.outputs['data_path']\n",
    "    )\n",
    "\n",
    "    train_model_task = train_model_comp(\n",
    "        preprocess_data_task.output\n",
    "    ).set_gpu_limit(1)\n",
    "    \n",
    "    evaluate_model_task = evaluate_model_comp(\n",
    "        preprocess_data_task.output,\n",
    "        train_model_task.output\n",
    "    ).set_gpu_limit(1)\n",
    "\n",
    "    convert_model_to_onnx_task = convert_model_to_onnx_comp(\n",
    "        train_model_task.output\n",
    "    )\n",
    "\n",
    "    upload_model_task = upload_model_comp(\n",
    "        convert_model_to_onnx_task.output,\n",
    "        minio_url,\n",
    "        minio_user,\n",
    "        minio_pass,\n",
    "        model_name=model_name\n",
    "    )\n",
    "\n",
    "    deploy_model_with_kserve_task = deploy_model_with_kserve_comp(\n",
    "        model_name=model_name\n",
    "    )\n",
    "\n",
    "    deploy_model_with_kserve_task.after(upload_model_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Run the pipline within an experiment\n",
    "After defining the pipeline arguments the pipeline run is executed. Click on *Run details* which will appear below the cell and view the run of the pipeline inside the Kubeflow Pipelines UI opening in the browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/experiments/details/0b0d9a68-91e4-494a-a97f-92ac03cd98ea\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/runs/details/1eca175a-2d54-4dff-942f-d2c55c143554\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RunPipelineResult(run_id=1eca175a-2d54-4dff-942f-d2c55c143554)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify argument values for your pipeline run.\n",
    "arguments = {\n",
    "    'dataset_url': DATASET_URL,\n",
    "    'dataset_file_name': DATASET_FILE_NAME,\n",
    "    'data_dir': '/train/data',\n",
    "    'prep_data_dir': '/train/prep_data',\n",
    "    'model_dir': '/train/model',\n",
    "    'model_name': MODEL_NAME,\n",
    "    'minio_url': MINIO_URL,\n",
    "    'minio_user': MINIO_USER,\n",
    "    'minio_pass': MINIO_PASS\n",
    "}\n",
    "\n",
    "client.create_run_from_pipeline_func(\n",
    "    fingerprint_pipeline,\n",
    "    arguments=arguments,\n",
    "    namespace=NAMESPACE\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
